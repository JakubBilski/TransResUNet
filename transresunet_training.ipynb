{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "transresunet-lungs-segmentation.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "56613433-4d47-4c84-9ea2-349328ab4156",
        "_cell_guid": "6b3c7704-2f6b-4069-bd01-57fa92689802",
        "trusted": true,
        "id": "XfMupXbSWajk",
        "colab_type": "text"
      },
      "source": [
        "# TransResUNet: Improving U-Net Architecture for Robust Lungs Segmentation in Chest X-rays\n",
        "\n",
        "Reference paper can be accessed at - https://www.researchgate.net/publication/342038283_TransResUNet_Improving_U-Net_Architecture_for_Robust_Lungs_Segmentation_in_Chest_X-rays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "46205201-4561-4795-82a2-c4ada69c9942",
        "_cell_guid": "cfadae15-9ae6-47ac-952d-e75cb9fe7b13",
        "trusted": true,
        "id": "EV-YIE0YWajp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing required packages\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras import backend as keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e712dc8f-a8fa-4849-829e-52d9ee28c1d0",
        "_cell_guid": "7ebfdbaf-1e41-4a24-a464-eb2130d9c27f",
        "trusted": true,
        "id": "z5HQovlZWajw",
        "colab_type": "text"
      },
      "source": [
        "# 1. TransResUNet - Model Defination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e003c784-ade0-4140-8687-72e5d66c7026",
        "_cell_guid": "2223bf5d-b173-4746-a2c1-6440fd0936f5",
        "trusted": true,
        "id": "ErwnvLilWajx",
        "colab_type": "text"
      },
      "source": [
        "* ## Residual Path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f4d6af6e-5b0c-4fcb-94d3-3964f92ea1d6",
        "_cell_guid": "8026b7f1-5eb0-4a94-bbd9-3a27f118d81d",
        "trusted": true,
        "id": "2amWyLnpWajy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_block(inputs,filter_size):\n",
        "    \"\"\"\n",
        "    res_block -- Residual block for building res path\n",
        "    \n",
        "    Arguments:\n",
        "    inputs {<class 'tensorflow.python.framework.ops.Tensor'>} -- input for residual block\n",
        "    filter_size {int} -- convolutional filter size \n",
        "    \n",
        "    Returns:\n",
        "    add {<class 'tensorflow.python.framework.ops.Tensor'>} -- addition of two convolutional filter output  \n",
        "    \"\"\"\n",
        "    # First Conv2D layer\n",
        "    cb1 = Conv2D(filter_size,(3,3),padding = 'same',activation=\"relu\")(inputs)\n",
        "    # Second Conv2D layer parallel to the first one\n",
        "    cb2 = Conv2D(filter_size,(1,1),padding = 'same',activation=\"relu\")(inputs)\n",
        "    # Addition of cb1 and cb2\n",
        "    add = Add()([cb1,cb2])\n",
        "    \n",
        "    return add\n",
        "\n",
        "def res_path(inputs,filter_size,path_number):\n",
        "    \"\"\"\n",
        "    res_path -- residual path / modified skip connection\n",
        "    \n",
        "    Arguments:\n",
        "    inputs {<class 'tensorflow.python.framework.ops.Tensor'>} -- input for res path\n",
        "    filter_size {int} -- convolutional filter size \n",
        "    path_number {int} -- path identifier \n",
        "    \n",
        "    Returns:\n",
        "    skip_connection {<class 'tensorflow.python.framework.ops.Tensor'>} -- final res path\n",
        "    \"\"\"\n",
        "    # Minimum one residual block for every res path\n",
        "    skip_connection = res_block(inputs, filter_size)\n",
        "    \n",
        "    # Two serial residual blocks for res path 2\n",
        "    if path_number == 2:\n",
        "        skip_connection = res_block(skip_connection,filter_size)\n",
        "    \n",
        "    # Three serial residual blocks for res path 1\n",
        "    elif path_number == 1:\n",
        "        skip_connection = res_block(skip_connection,filter_size)\n",
        "        skip_connection = res_block(skip_connection,filter_size)\n",
        "    \n",
        "    return skip_connection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "32566bab-7f5a-4cc8-a1e0-93e93ab8691f",
        "_cell_guid": "1bed4801-de8f-41bf-a8ca-1987ee41f5e2",
        "trusted": true,
        "id": "Xy69M-8kWaj5",
        "colab_type": "text"
      },
      "source": [
        "* ## Decoder Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "660fece3-dd85-4f97-aeb2-a35ae282ed1c",
        "_cell_guid": "6bfb8264-6c32-4002-b0c2-3d6860218e28",
        "trusted": true,
        "id": "pR8jKyfXWaj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder_block(inputs, mid_channels, out_channels):\n",
        "    \n",
        "    \"\"\"\n",
        "    decoder_block -- decoder block formation\n",
        "    \n",
        "    Arguments:\n",
        "    inputs {<class 'tensorflow.python.framework.ops.Tensor'>} -- input for decoder block\n",
        "    mid_channels {int} -- no. of mid channels \n",
        "    out_channels {int} -- no. of out channels\n",
        "    \n",
        "    Returns:\n",
        "    db {<class 'tensorflow.python.framework.ops.Tensor'>} -- returning the decoder block\n",
        "    \"\"\"\n",
        "    conv_kwargs = dict(\n",
        "        activation='relu',\n",
        "        padding='same',\n",
        "        kernel_initializer='he_normal',\n",
        "        data_format='channels_last'  \n",
        "    )\n",
        "    \n",
        "    # Upsampling (nearest neighbor interpolation) layer\n",
        "    db = UpSampling2D(size=(2, 2))(inputs)\n",
        "    # First conv2D layer \n",
        "    db = Conv2D(mid_channels, 3, **conv_kwargs)(db)\n",
        "    # Second conv2D layer\n",
        "    db = Conv2D(out_channels, 3, **conv_kwargs)(db)\n",
        "\n",
        "    return db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4GPGK8IWaj9",
        "colab_type": "text"
      },
      "source": [
        "* ## Main Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IgAtcZZwWaj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TransResUNet(input_size=(512, 512, 1)):\n",
        "    \"\"\"\n",
        "    TransResUNet -- main architecture of TransResUNet\n",
        "    \n",
        "    Arguments:\n",
        "    input_size {tuple} -- size of input image\n",
        "    \n",
        "    Returns:\n",
        "    model {<class 'tensorflow.python.keras.engine.training.Model'>} -- final model\n",
        "    \"\"\"\n",
        "    \n",
        "    # Input \n",
        "    inputs = Input(input_size)\n",
        "    inp = inputs\n",
        "    input_shape = input_size\n",
        "    \n",
        "    # Handling input channels \n",
        "    # input with 1 channel will be converted to 3 channels to be compatible with VGG16 pretrained encoder \n",
        "    if input_size[-1] < 3:\n",
        "        inp = Conv2D(3, 1)(inputs)                         \n",
        "        input_shape = (input_size[0], input_size[0], 3)  \n",
        "    else:\n",
        "        inp = inputs\n",
        "        input_shape = input_size\n",
        "\n",
        "    # VGG16 with imagenet weights\n",
        "    encoder = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "       \n",
        "    # First encoder block\n",
        "    enc1 = encoder.get_layer(name='block1_conv1')(inp)\n",
        "    enc1 = encoder.get_layer(name='block1_conv2')(enc1)\n",
        "    # Second encoder block\n",
        "    enc2 = MaxPooling2D(pool_size=(2, 2))(enc1)\n",
        "    enc2 = encoder.get_layer(name='block2_conv1')(enc2)\n",
        "    enc2 = encoder.get_layer(name='block2_conv2')(enc2)\n",
        "    # Third encoder block\n",
        "    enc3 = MaxPooling2D(pool_size=(2, 2))(enc2)\n",
        "    enc3 = encoder.get_layer(name='block3_conv1')(enc3)\n",
        "    enc3 = encoder.get_layer(name='block3_conv2')(enc3)\n",
        "    enc3 = encoder.get_layer(name='block3_conv3')(enc3)\n",
        "\n",
        "    # Center block\n",
        "    center = MaxPooling2D(pool_size=(2, 2))(enc3)\n",
        "    center = decoder_block(center, 512, 256)\n",
        "\n",
        "    # Decoder block corresponding to third encoder\n",
        "    res_path3 = res_path(enc3,128,3)\n",
        "    dec3 = concatenate([res_path3, center], axis=3)\n",
        "    dec3 = decoder_block(dec3, 256, 64)\n",
        "    # Decoder block corresponding to second encoder\n",
        "    res_path2 = res_path(enc2,64,2)\n",
        "    dec2 = concatenate([res_path2, dec3], axis=3)\n",
        "    dec2 = decoder_block(dec2, 128, 64)\n",
        "    # Final Block concatenation with first encoded feature \n",
        "    res_path1 = res_path(enc1,32,1)\n",
        "    dec1 = concatenate([res_path1, dec2], axis=3)\n",
        "    dec1 = Conv2D(32, 3, padding='same', kernel_initializer='he_normal')(dec1)\n",
        "    dec1 = ReLU()(dec1)\n",
        "   \n",
        "\n",
        "    # Output\n",
        "    out = Conv2D(1, 1)(dec1)\n",
        "    out = Activation('sigmoid')(out)  \n",
        "    \n",
        "    # Final model\n",
        "    model = Model(inputs=[inputs], outputs=[out])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChX_0SEPWakB",
        "colab_type": "text"
      },
      "source": [
        "* ## Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "88e4a21a-be27-4dd7-8263-15345584ae18",
        "_cell_guid": "80c7507f-f3ec-44d1-a2c2-0d614def2270",
        "trusted": true,
        "id": "UKE23M6-WakB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = TransResUNet()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3ece4f5f-9a8a-4851-a081-4c6a9d92b1b6",
        "_cell_guid": "6907dd6b-aa0a-4b9c-9d01-4b7f9804c161",
        "trusted": true,
        "id": "I_K9kV0JWakG",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data preparation\n",
        "Reference: https://www.kaggle.com/eduardomineo/u-net-lung-segmentation-montgomery-shenzhen\n",
        "\n",
        "Prepare the input segmentation directory structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6c93e16e-7845-4d13-88b7-9cc43b66a490",
        "_cell_guid": "0b5e0b4c-931f-4236-a7c5-e2f527c79474",
        "trusted": true,
        "id": "NMihs_m8WakG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ../input/segmentation\n",
        "!mkdir ../input/segmentation/test\n",
        "!mkdir ../input/segmentation/train\n",
        "!mkdir ../input/segmentation/train/augmentation\n",
        "!mkdir ../input/segmentation/train/image\n",
        "!mkdir ../input/segmentation/train/mask\n",
        "!mkdir ../input/segmentation/train/dilate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6e219ccf-0ef6-4102-ad61-9ce649a98f8e",
        "_cell_guid": "08bc3433-63f3-45e0-9983-ec77dc9cdbe1",
        "trusted": true,
        "id": "IjJsWBRyWakK",
        "colab_type": "text"
      },
      "source": [
        "Define appropriate constants for directory paths and training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e3a242a9-d728-4fbf-ba8f-2ac6cfe92e17",
        "_cell_guid": "33e9b60c-f6f2-4571-b589-a7469e842493",
        "trusted": true,
        "id": "ZXgvWPu6WakL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIR = os.path.join(\"..\", \"input\")\n",
        "\n",
        "SEGMENTATION_DIR = os.path.join(INPUT_DIR, \"segmentation\")\n",
        "SEGMENTATION_TEST_DIR = os.path.join(SEGMENTATION_DIR, \"test\")\n",
        "SEGMENTATION_TRAIN_DIR = os.path.join(SEGMENTATION_DIR, \"train\")\n",
        "SEGMENTATION_AUG_DIR = os.path.join(SEGMENTATION_TRAIN_DIR, \"augmentation\")\n",
        "SEGMENTATION_IMAGE_DIR = os.path.join(SEGMENTATION_TRAIN_DIR, \"image\")\n",
        "SEGMENTATION_MASK_DIR = os.path.join(SEGMENTATION_TRAIN_DIR, \"mask\")\n",
        "SEGMENTATION_DILATE_DIR = os.path.join(SEGMENTATION_TRAIN_DIR, \"dilate\")\n",
        "SEGMENTATION_SOURCE_DIR = os.path.join(INPUT_DIR, \\\n",
        "                                       \"pulmonary-chest-xray-abnormalities\")\n",
        "\n",
        "SHENZHEN_TRAIN_DIR = os.path.join(SEGMENTATION_SOURCE_DIR, \"ChinaSet_AllFiles\", \\\n",
        "                                  \"ChinaSet_AllFiles\")\n",
        "SHENZHEN_IMAGE_DIR = os.path.join(SHENZHEN_TRAIN_DIR, \"CXR_png\")\n",
        "SHENZHEN_MASK_DIR = os.path.join(INPUT_DIR, \"shcxr-lung-mask\", \"mask\", \"mask\")\n",
        "\n",
        "MONTGOMERY_TRAIN_DIR = os.path.join(SEGMENTATION_SOURCE_DIR, \\\n",
        "                                    \"Montgomery\", \"MontgomerySet\")\n",
        "MONTGOMERY_IMAGE_DIR = os.path.join(MONTGOMERY_TRAIN_DIR, \"CXR_png\")\n",
        "MONTGOMERY_LEFT_MASK_DIR = os.path.join(MONTGOMERY_TRAIN_DIR, \\\n",
        "                                        \"ManualMask\", \"leftMask\")\n",
        "MONTGOMERY_RIGHT_MASK_DIR = os.path.join(MONTGOMERY_TRAIN_DIR, \\\n",
        "                                         \"ManualMask\", \"rightMask\")\n",
        "\n",
        "DILATE_KERNEL = np.ones((15, 15), np.uint8)\n",
        "\n",
        "BATCH_SIZE=4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0e3d7544-e576-416c-b0c7-56263db5b116",
        "_cell_guid": "e487e86a-2846-4bf0-948f-233c209ed9f8",
        "trusted": true,
        "id": "QkqC3XsFWakQ",
        "colab_type": "text"
      },
      "source": [
        "1. Combine left and right lung segmentation masks of Montgomery chest x-rays\n",
        "1. Resize images to 512x512 pixels\n",
        "1. Dilate masks to gain more information on the edge of lungs\n",
        "1. Split images into training and test datasets\n",
        "1. Write images to /segmentation directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "03120cff-c4c5-4b9b-b6fb-ebe4b322d63f",
        "_cell_guid": "075e133a-a5e4-462b-98dc-c8a8be253699",
        "trusted": true,
        "id": "qgzLsIGEWakR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(91)\n",
        "montgomery_left_mask_dir = glob(os.path.join(MONTGOMERY_LEFT_MASK_DIR, '*.png'))\n",
        "montgomery_left_mask_dir_temp = random.sample(montgomery_left_mask_dir, len(montgomery_left_mask_dir))\n",
        "montgomery_test = montgomery_left_mask_dir_temp[0:41]\n",
        "montgomery_train= montgomery_left_mask_dir_temp[41:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9f35e815-9873-4659-9474-ed0e722bad70",
        "_cell_guid": "d5800dce-57ba-49a7-a86c-d1b663c82e11",
        "trusted": true,
        "id": "of885YU_WakX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for left_image_file in tqdm(montgomery_left_mask_dir):\n",
        "    base_file = os.path.basename(left_image_file)\n",
        "    image_file = os.path.join(MONTGOMERY_IMAGE_DIR, base_file)\n",
        "    right_image_file = os.path.join(MONTGOMERY_RIGHT_MASK_DIR, base_file)\n",
        "\n",
        "    image = cv2.imread(image_file)\n",
        "    left_mask = cv2.imread(left_image_file, cv2.IMREAD_GRAYSCALE)\n",
        "    right_mask = cv2.imread(right_image_file, cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "    image = cv2.resize(image, (512, 512))\n",
        "    \n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    left_mask = cv2.resize(left_mask, (512, 512))\n",
        "    right_mask = cv2.resize(right_mask, (512, 512))\n",
        "    \n",
        "    mask = np.maximum(left_mask, right_mask)\n",
        "    mask_dilate = cv2.dilate(mask, DILATE_KERNEL, iterations=1)\n",
        "    \n",
        "    if (left_image_file in montgomery_train):\n",
        "        cv2.imwrite(os.path.join(SEGMENTATION_IMAGE_DIR, base_file), \\\n",
        "                    image)\n",
        "        cv2.imwrite(os.path.join(SEGMENTATION_MASK_DIR, base_file), \\\n",
        "                    mask)\n",
        "        cv2.imwrite(os.path.join(SEGMENTATION_DILATE_DIR, base_file), \\\n",
        "                    mask_dilate)\n",
        "    else:\n",
        "        filename, fileext = os.path.splitext(base_file)\n",
        "        cv2.imwrite(os.path.join(SEGMENTATION_TEST_DIR, base_file), \\\n",
        "                    image)\n",
        "        cv2.imwrite(os.path.join(SEGMENTATION_TEST_DIR, \\\n",
        "                                 \"%s_mask%s\" % (filename, fileext)), mask)\n",
        "        cv2.imwrite(os.path.join(SEGMENTATION_TEST_DIR, \\\n",
        "                                 \"%s_dilate%s\" % (filename, fileext)), mask_dilate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "7bf97940-67e9-4582-938a-5d90ccaa015d",
        "_cell_guid": "1dc0ea00-d959-47ae-b146-5abedd8cd614",
        "trusted": true,
        "id": "Zy_JzGgKWakc",
        "colab_type": "text"
      },
      "source": [
        "Define some useful functions to display images with segmentation as overlays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5130c132-340f-460c-9cca-c0eeeba0b44a",
        "_cell_guid": "ac88c130-96e4-42b8-ae98-9e742ba50e56",
        "trusted": true,
        "id": "WWVDqJQvWakd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_colored_dilate(image, mask_image, dilate_image):\n",
        "    mask_image_gray = cv2.cvtColor(mask_image, cv2.COLOR_BGR2GRAY)\n",
        "    dilate_image_gray = cv2.cvtColor(dilate_image, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    mask = cv2.bitwise_and(mask_image, mask_image, mask=mask_image_gray)\n",
        "    dilate = cv2.bitwise_and(dilate_image, dilate_image, mask=dilate_image_gray)\n",
        "    \n",
        "    mask_coord = np.where(mask!=[0,0,0])\n",
        "    dilate_coord = np.where(dilate!=[0,0,0])\n",
        "\n",
        "    mask[mask_coord[0],mask_coord[1],:]=[255,0,0]\n",
        "    dilate[dilate_coord[0],dilate_coord[1],:] = [0,0,255]\n",
        "\n",
        "    ret = cv2.addWeighted(image, 0.7, dilate, 0.3, 0)\n",
        "    ret = cv2.addWeighted(ret, 0.7, mask, 0.3, 0)\n",
        "\n",
        "    return ret\n",
        "\n",
        "def add_colored_mask(image, mask_image):\n",
        "    mask_image_gray = cv2.cvtColor(mask_image, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    mask = cv2.bitwise_and(mask_image, mask_image, mask=mask_image_gray)\n",
        "    \n",
        "    mask_coord = np.where(mask!=[0,0,0])\n",
        "\n",
        "    mask[mask_coord[0],mask_coord[1],:]=[255,0,0]\n",
        "\n",
        "    ret = cv2.addWeighted(image, 0.7, mask, 0.3, 0)\n",
        "\n",
        "    return ret\n",
        "\n",
        "def diff_mask(ref_image, mask_image):\n",
        "    mask_image_gray = cv2.cvtColor(mask_image, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    mask = cv2.bitwise_and(mask_image, mask_image, mask=mask_image_gray)\n",
        "    \n",
        "    mask_coord = np.where(mask!=[0,0,0])\n",
        "\n",
        "    mask[mask_coord[0],mask_coord[1],:]=[255,0,0]\n",
        "\n",
        "    ret = cv2.addWeighted(ref_image, 0.7, mask, 0.3, 0)\n",
        "    return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c454af90-1ed3-453a-a0a8-51f3153b6a3c",
        "_cell_guid": "49a58fc7-ef4d-4a5e-b15f-411f9f3832e6",
        "trusted": true,
        "id": "WjiK91jVWakh",
        "colab_type": "text"
      },
      "source": [
        "Show some Montgomery chest x-rays and its lung segmentation masks from training and test dataset to verify the procedure above. In merged image it is possible to see the difference between the dilated mask in blue and the original mask in red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4307b48d-e159-4b5d-8c73-8a4ef6ee94e3",
        "_cell_guid": "5db4a702-ce0d-48db-960c-4bd6a8ebbc58",
        "trusted": true,
        "_kg_hide-output": false,
        "_kg_hide-input": false,
        "id": "5XSWPy7-Wakh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_file = os.path.basename(montgomery_train[0])\n",
        "\n",
        "image_file = os.path.join(SEGMENTATION_IMAGE_DIR, base_file)\n",
        "mask_image_file = os.path.join(SEGMENTATION_MASK_DIR, base_file)\n",
        "dilate_image_file = os.path.join(SEGMENTATION_DILATE_DIR, base_file)\n",
        "\n",
        "image = cv2.imread(image_file)\n",
        "mask_image = cv2.imread(mask_image_file)\n",
        "dilate_image = cv2.imread(dilate_image_file)\n",
        "merged_image = add_colored_dilate(image, mask_image, dilate_image)\n",
        "                          \n",
        "fig, axs = plt.subplots(2, 4, figsize=(15, 8))\n",
        "plt.set_cmap('gray')\n",
        "\n",
        "axs[0, 0].set_title(\"X-Ray\")\n",
        "axs[0, 0].imshow(image)\n",
        "\n",
        "axs[0, 1].set_title(\"Mask\")\n",
        "axs[0, 1].imshow(mask_image)\n",
        "\n",
        "axs[0, 2].set_title(\"Dilate\")\n",
        "axs[0, 2].imshow(dilate_image)\n",
        "\n",
        "axs[0, 3].set_title(\"Merged\")\n",
        "axs[0, 3].imshow(merged_image)\n",
        "\n",
        "base_file = os.path.basename(montgomery_test[0])\n",
        "filename, fileext = os.path.splitext(base_file)\n",
        "image_file = os.path.join(SEGMENTATION_TEST_DIR, base_file)\n",
        "mask_image_file = os.path.join(SEGMENTATION_TEST_DIR, \\\n",
        "                               \"%s_mask%s\" % (filename, fileext))\n",
        "dilate_image_file = os.path.join(SEGMENTATION_TEST_DIR, \\\n",
        "                                 \"%s_dilate%s\" % (filename, fileext))\n",
        "\n",
        "image = cv2.imread(image_file)\n",
        "mask_image = cv2.imread(mask_image_file)\n",
        "dilate_image = cv2.imread(dilate_image_file)\n",
        "merged_image = add_colored_dilate(image, mask_image, dilate_image)\n",
        "\n",
        "axs[1, 0].set_title(\"X-Ray\")\n",
        "axs[1, 0].imshow(image)\n",
        "\n",
        "axs[1, 1].set_title(\"Mask\")\n",
        "axs[1, 1].imshow(mask_image)\n",
        "\n",
        "axs[1, 2].set_title(\"Dilate\")\n",
        "axs[1, 2].imshow(dilate_image)\n",
        "\n",
        "axs[1, 3].set_title(\"Merged\")\n",
        "axs[1, 3].imshow(merged_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "00a3a071-e370-4ada-89dd-5d2a882f1e50",
        "_cell_guid": "946f6d6d-aafa-4b07-b887-1cd30adc8360",
        "trusted": true,
        "id": "cLhAGJh1Wakl",
        "colab_type": "text"
      },
      "source": [
        "Print the count of images and segmentation lung masks available to test and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8095bd74-870a-4b3a-8885-a7176ec6ff9e",
        "_cell_guid": "e1021f56-829c-4fb4-ba20-86b86b5bea63",
        "trusted": true,
        "scrolled": false,
        "id": "97s8E3sZWakl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_files = glob(os.path.join(SEGMENTATION_IMAGE_DIR, \"*.png\"))\n",
        "test_files = glob(os.path.join(SEGMENTATION_TEST_DIR, \"*.png\"))\n",
        "mask_files = glob(os.path.join(SEGMENTATION_MASK_DIR, \"*.png\"))\n",
        "dilate_files = glob(os.path.join(SEGMENTATION_DILATE_DIR, \"*.png\"))\n",
        "\n",
        "(len(train_files), \\\n",
        " len(test_files), \\\n",
        " len(mask_files), \\\n",
        " len(dilate_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ee9df889-ff17-4ecf-a6d3-d0b00422f8e0",
        "_cell_guid": "d6a64ddc-fde4-43c6-b044-cdad8c6367ba",
        "trusted": true,
        "id": "zgIkeQtMWako",
        "colab_type": "text"
      },
      "source": [
        "# 3. Segmentation training\n",
        "\n",
        "References: https://github.com/zhixuhao/unet/, https://github.com/jocicmarko/ultrasound-nerve-segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "054ba93f-82b0-4e0a-9ab9-23725f4bf250",
        "_cell_guid": "c5dac174-52b6-4c47-a583-bb7a6e4ff1bb",
        "trusted": true,
        "id": "gsmqdi2TWako",
        "colab_type": "text"
      },
      "source": [
        "Data augmentation helper function for training the net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "177aea94-6407-403d-a347-94df09593b06",
        "_cell_guid": "c115483e-de47-4337-8a14-8492c072a92a",
        "trusted": true,
        "id": "TCIvgkj_Wakp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From: https://github.com/zhixuhao/unet/blob/master/data.py\n",
        "def train_generator(batch_size, train_path, image_folder, mask_folder, aug_dict,\n",
        "        image_color_mode=\"grayscale\",\n",
        "        mask_color_mode=\"grayscale\",\n",
        "        image_save_prefix=\"image\",\n",
        "        mask_save_prefix=\"mask\",\n",
        "        save_to_dir=None,\n",
        "        target_size=(256,256),\n",
        "        seed=1):\n",
        "    '''\n",
        "    can generate image and mask at the same time use the same seed for\n",
        "    image_datagen and mask_datagen to ensure the transformation for image\n",
        "    and mask is the same if you want to visualize the results of generator,\n",
        "    set save_to_dir = \"your path\"\n",
        "    '''\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    \n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [image_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = image_save_prefix,\n",
        "        seed = seed)\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [mask_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = mask_save_prefix,\n",
        "        seed = seed)\n",
        "\n",
        "    train_gen = zip(image_generator, mask_generator)\n",
        "    \n",
        "    for (img, mask) in train_gen:\n",
        "        img, mask = adjust_data(img, mask)\n",
        "        yield (img,mask)\n",
        "\n",
        "def adjust_data(img,mask):\n",
        "    img = img / 255\n",
        "    mask = mask / 255\n",
        "    mask[mask > 0.5] = 1\n",
        "    mask[mask <= 0.5] = 0\n",
        "    \n",
        "    return (img, mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a599bc2f-5dbb-46f2-8e91-136494e7f86d",
        "_cell_guid": "9aef16ad-d5f5-4758-8333-251e006d1c5e",
        "trusted": true,
        "id": "ADolfpCzWaks",
        "colab_type": "text"
      },
      "source": [
        "Metric functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "11cd554e-670c-44b9-a5dc-9c79157d4167",
        "_cell_guid": "0f23f005-477c-4305-b264-c9ac4874035f",
        "trusted": true,
        "id": "hhOxwMfCWaks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = keras.flatten(y_true)\n",
        "    y_pred_f = keras.flatten(y_pred)\n",
        "    intersection = keras.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "90fd414a-57ac-4bfd-b111-b344bd4695b1",
        "_cell_guid": "f5497908-88a8-4ba5-8280-6f89fbcc886b",
        "trusted": true,
        "id": "h10GKRD8Wakv",
        "colab_type": "text"
      },
      "source": [
        "Helper functions to load test chest x-ray images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e6a80fc5-aca2-4baf-93e8-1e5917d7cfeb",
        "_cell_guid": "e43ca7d7-7798-474d-b8cb-883e84af6a06",
        "trusted": true,
        "id": "V2RzCqLZWakv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From: https://github.com/zhixuhao/unet/blob/master/data.py\n",
        "def test_load_image(test_file, target_size=(256,256)):\n",
        "    img = cv2.imread(test_file, cv2.IMREAD_GRAYSCALE)\n",
        "    img = img / 255\n",
        "    img = cv2.resize(img, target_size)\n",
        "    img = np.reshape(img, img.shape + (1,))\n",
        "    img = np.reshape(img,(1,) + img.shape)\n",
        "    return img\n",
        "\n",
        "def test_generator(test_files, target_size=(256,256)):\n",
        "    for test_file in test_files:\n",
        "        yield test_load_image(test_file, target_size)\n",
        "        \n",
        "def save_result(save_path, npyfile, test_files):\n",
        "    for i, item in enumerate(npyfile):\n",
        "        result_file = test_files[i]\n",
        "        img = (item[:, :, 0] * 255.).astype(np.uint8)\n",
        "\n",
        "        filename, fileext = os.path.splitext(os.path.basename(result_file))\n",
        "\n",
        "        result_file = os.path.join(save_path, \"%s_predict%s\" % (filename, fileext))\n",
        "\n",
        "        cv2.imwrite(result_file, img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "18fab05c-201c-41d8-9786-e5e5f7356cac",
        "_cell_guid": "8e2beac7-9d06-43bb-a06e-0c8066c0a04d",
        "trusted": true,
        "id": "tLSEt3hLWak1",
        "colab_type": "text"
      },
      "source": [
        "Select test and validation files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "98b9ed1a-3769-42c7-8dbe-2401562f930a",
        "_cell_guid": "6956ffa7-b795-457a-8bd0-3935a5187dad",
        "trusted": true,
        "id": "ab0aSlSAWak1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_suffix(base_file, suffix):\n",
        "    filename, fileext = os.path.splitext(base_file)\n",
        "    return \"%s_%s%s\" % (filename, suffix, fileext)\n",
        "\n",
        "test_files = [test_file for test_file in glob(os.path.join(SEGMENTATION_TEST_DIR, \"*.png\")) \\\n",
        "              if (\"_mask\" not in test_file \\\n",
        "                  and \"_dilate\" not in test_file \\\n",
        "                  and \"_predict\" not in test_file)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "018879de-465c-4ae0-bf23-b094b4823047",
        "_cell_guid": "37673d53-7e0a-436d-bb17-c9dcc742e7a4",
        "trusted": true,
        "id": "11BG9UKIWak4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x = []\n",
        "for i in test_files:\n",
        "    test_x.append(test_load_image(i, target_size=(512, 512)))\n",
        "    \n",
        "test_x = np.array(test_x)\n",
        "val_x = test_x[27:,0,:,:]\n",
        "test_x = test_x[:27,0,:,:]\n",
        "val_x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a16c2052-5c07-4c9b-9a77-5892805a588f",
        "_cell_guid": "b4ae3596-dfb7-4bc5-b65c-aa04ccf5bde5",
        "trusted": true,
        "id": "RTFtWdF-Wak7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_y = []\n",
        "for i in test_files:\n",
        "    test_y.append(test_load_image(add_suffix(i, \"dilate\"), target_size=(512, 512)))\n",
        "\n",
        "test_y = np.array(test_y)\n",
        "val_y = test_y[27:,0,:,:]\n",
        "test_y = test_y[:27,0,:,:]\n",
        "val_y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "177471d2-4b3b-4db6-914a-080df9fc17d6",
        "_cell_guid": "39a8a871-43c9-4442-afcb-e3dfdeea466f",
        "trusted": true,
        "id": "sptxmFprWak-",
        "colab_type": "text"
      },
      "source": [
        "Configuring the hyperparameter and Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "003e544e-e113-4a37-ac7a-d205dcf08c4f",
        "_cell_guid": "0c3e2510-0baf-4ff5-8d31-edd7277c52ce",
        "trusted": true,
        "id": "blZNXlyHWak-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 4\n",
        "EPOCH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "40345e58-6e65-4fb5-9b0d-8562adcbcc0f",
        "_cell_guid": "e38136fa-c997-4ee0-bc14-9d0c47d422a6",
        "trusted": true,
        "scrolled": false,
        "id": "rnfdyCfDWalB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator_args = dict(rotation_range=0.2,\n",
        "                            width_shift_range=0.05,\n",
        "                            height_shift_range=0.05,\n",
        "                            shear_range=0.05,\n",
        "                            zoom_range=0.05,\n",
        "                            horizontal_flip=True,\n",
        "                            fill_mode='nearest')\n",
        "\n",
        "train_gen = train_generator(BATCH_SIZE,\n",
        "                            SEGMENTATION_TRAIN_DIR,\n",
        "                            'image',\n",
        "                            'dilate', \n",
        "                            train_generator_args,\n",
        "                            target_size=(512,512),\n",
        "                            save_to_dir=os.path.abspath(SEGMENTATION_AUG_DIR))\n",
        "\n",
        "model = TransResUNet()\n",
        "\n",
        "model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, \\\n",
        "                  metrics=[dice_coef, 'binary_accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('transresunet_seg.hdf5', \n",
        "                                   monitor='loss', \n",
        "                                   verbose=1, \n",
        "                                   save_best_only=True)\n",
        "\n",
        "history = model.fit_generator(train_gen,\n",
        "                              steps_per_epoch=len(train_files) / BATCH_SIZE, \n",
        "                              epochs=EPOCH, \n",
        "                              callbacks=[model_checkpoint],\n",
        "                              validation_data = (val_x, val_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "60e4a071-07bf-4dbd-a36a-335f501c89f9",
        "_cell_guid": "da399531-c1ca-417a-b0c0-2beb95490652",
        "trusted": true,
        "id": "ttx0WYn1WalE",
        "colab_type": "text"
      },
      "source": [
        "Show some results from model fitting history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "71a73e11-1a75-49a7-bd02-4dc8d90f6689",
        "_cell_guid": "7ce2a504-1d69-4596-bf6a-c9d2712c7ea9",
        "trusted": true,
        "id": "oWMhz08iWalE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize = (15, 4))\n",
        "\n",
        "training_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "\n",
        "training_accuracy = history.history['dice_coef']\n",
        "validation_accuracy = history.history['val_dice_coef']\n",
        "\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "axs[0].plot(epoch_count, training_loss, 'r--')\n",
        "axs[0].plot(epoch_count, validation_loss, 'b-')\n",
        "axs[0].legend(['Training Loss', 'Validation Loss'])\n",
        "\n",
        "axs[1].plot(epoch_count, training_accuracy, 'r--')\n",
        "axs[1].plot(epoch_count, validation_accuracy, 'b-')\n",
        "axs[1].legend(['Training Dice Coef', 'Validation Dice Coef'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "daec4895-978e-492d-b596-861e155df4c5",
        "_cell_guid": "eeb903c5-be0a-4d6b-b0f1-e65bba718777",
        "trusted": true,
        "id": "pWMyh0fHWalH",
        "colab_type": "text"
      },
      "source": [
        "Make lung segmentation predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "04ce840f-0de7-46c5-b880-c3265909069f",
        "_cell_guid": "f8ca6f57-d3c2-4a98-9aa2-b7b8a50fd42f",
        "trusted": true,
        "id": "_HGDvaeVWalI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen = test_generator(test_files, target_size=(512,512))\n",
        "results = model.predict_generator(test_gen, len(test_files), verbose=1)\n",
        "save_result(SEGMENTATION_TEST_DIR, results, test_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ed1c46e2-1241-4c5b-af1f-3b4f5583a61e",
        "_cell_guid": "c819a5e5-4a6b-4fc1-a980-3ef49bbd1417",
        "trusted": true,
        "id": "SxMSn-trWalL",
        "colab_type": "text"
      },
      "source": [
        "# 4. Test Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f06c5553-460f-41a8-8bbf-1625f43a903e",
        "_cell_guid": "b4ab73bd-6475-4d41-918f-a47fdaa98b2a",
        "trusted": true,
        "id": "yWUFd6-ZWalM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(test_x,test_y, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}